 YouTube Video Recommendation System

A sophisticated machine learning-powered recommendation engine that combines YouTube data scraping with a two-tower neural network architecture to provide personalized video recommendations.

 ğŸ¯ Project Overview

This project implements a complete recommendation pipeline consisting of:
- **YouTube Data Scraping**: Automated collection of video metadata and transcripts
- **Two-Tower Neural Network**: Deep learning model for personalized recommendations
- **Interactive Web Interface**: Streamlit-based UI for real-time recommendations
- **FAISS Integration**: High-performance similarity search for scalable recommendations

ğŸ—ï¸ Architecture

 Core Components

1. Data Collection Layer (youtube_scraper/)
   - YouTube API integration for video metadata
   - Transcript extraction using YouTube Transcript API
   - Airtable integration for data storage and deduplication

2. Machine Learning Layer** (model.py , util.py)
   - Two-Tower neural network architecture
   - User and item embeddings with contextual features
   - FAISS-powered approximate nearest neighbor search

3. Application Layer** (app.py, main.py)
   - Streamlit web interface
   - Real-time recommendation generation
   - Interactive user profiling

 Quick Start

 Prerequisites

```bash
# Core dependencies
pip install torch streamlit faiss-cpu pandas numpy scikit-learn

# YouTube scraping dependencies
pip install requests youtube-transcript-api google-api-python-client
```

### Installation

1. **Clone the repository**
   ```bash
   git clone <repository-url>
   cd ZovxLabs-Internship-main
   ```

2. **Install dependencies**
   ```bash
   pip install -r youtube_scraper/requirements.txt
   pip install torch streamlit faiss-cpu pandas numpy scikit-learn google-api-python-client
   ```

3. **Configure API Keys**
   ```bash
   # Set your YouTube Data API key in:
   # - main.py (line 11)
   # - youtube_scraper/ytscrap.py (line 6)
   
   # Set Airtable credentials in youtube_scraper/airtablescript.py (lines 8-10)
   ```

### Running the Application

#### Option 1: Simple Recommendation Interface
```bash
streamlit run main.py
```
Access the application at `http://localhost:8501`

#### Option 2: Advanced Two-Tower Model Interface
```bash
# First, ensure you have a trained model (model.pth)
streamlit run app.py
```

#### Option 3: Data Collection Pipeline
```bash
cd youtube_scraper
python ytscrap.py          # Scrape videos and transcripts
python airtablescript.py   # Upload to Airtable
```

## ğŸ§  Model Architecture

### Two-Tower Neural Network

The recommendation system uses a two-tower architecture that learns separate representations for users and items:

```python
User Tower:
â”œâ”€â”€ User Embedding (32D)
â”œâ”€â”€ Time-of-Day Embedding (32D)
â”œâ”€â”€ Device Type Embedding (32D)
â””â”€â”€ Fully Connected Layer (96D â†’ 32D)

Item Tower:
â”œâ”€â”€ Item Embedding (32D)
â”œâ”€â”€ Category Embedding (32D)
â””â”€â”€ Fully Connected Layer (64D â†’ 32D)

Final Score: dot_product(user_vector, item_vector)
```

### Key Features

- **Contextual Embeddings**: Time-of-day and device type awareness
- **Scalable Architecture**: FAISS integration for efficient similarity search
- **Real-time Inference**: Optimized for low-latency recommendations
- **Flexible Item Representation**: Category-aware item embeddings

## ğŸ“ Project Structure

```
ZovxLabs-Internship-main/
â”œâ”€â”€ app.py                    # Advanced Streamlit interface (Two-Tower)
â”œâ”€â”€ main.py                   # Simple Streamlit interface (YouTube API)
â”œâ”€â”€ model.py                  # Two-Tower model definition
â”œâ”€â”€ util.py                   # FAISS utilities and recommendation logic
â”œâ”€â”€ model.pth                 # Trained model weights (generated)
â””â”€â”€ youtube_scraper/
    â”œâ”€â”€ ytscrap.py           # YouTube video and transcript scraper
    â”œâ”€â”€ airtablescript.py    # Airtable integration script
    â”œâ”€â”€ dag.py               # (Empty) Airflow DAG placeholder
    â”œâ”€â”€ requirements.txt     # Scraping dependencies
    â””â”€â”€ *.jsonl             # Generated transcript data files
```

## ğŸ”§ Technical Details

### Data Flow

1. **Collection**: YouTube videos â†’ Transcripts â†’ Metadata
2. **Processing**: Raw data â†’ Embeddings â†’ Feature vectors
3. **Training**: User-item interactions â†’ Neural network weights
4. **Inference**: User profile â†’ Similarity search â†’ Ranked recommendations

### Model Training

The system supports two training approaches:

1. **Simple Training** (`main.py`): 
   - Real-time training on YouTube trending videos
   - Simulated user interactions
   - BCELoss optimization

2. **Advanced Training** (`model.py`):
   - Pre-trained embeddings with categorical features
   - Batch training with custom datasets
   - Dot-product similarity optimization

### Performance Considerations

- **FAISS Indexing**: O(log n) similarity search
- **Embedding Normalization**: L2 normalization for stable similarities
- **Batch Processing**: Efficient GPU/CPU utilization
- **Memory Optimization**: Compressed embedding storage

## ğŸ® Usage Examples

### Basic Recommendation

```python
# Generate recommendations for a user
user_vector = get_user_vector(model, user_id=42, 
                             time_str="Evening", 
                             device_str="Mobile")
recommendations = recommend_top_k(user_vector, item_vectors, 
                                 item_ids, top_k=10)
```

### Data Collection

```python
# Scrape channel videos
videos = fetch_all_videos_with_titles(API_KEY, CHANNEL_ID)

# Extract transcripts
for video in videos:
    transcript = fetch_transcript(video['video_id'])
    # Process transcript...
```

## ğŸ” Security & Configuration

### API Keys Required

- **YouTube Data API v3**: For video metadata and trending content
- **Airtable API** (Optional): For data storage and management

### Environment Setup

Create a `.env` file (not included in repo):
```bash
YOUTUBE_API_KEY=your_youtube_api_key
AIRTABLE_API_KEY=your_airtable_key
AIRTABLE_BASE_ID=your_base_id
```

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

## ğŸ“ˆ Future Enhancements

- [ ] Multi-modal embeddings (text + visual features)
- [ ] Online learning with user feedback
- [ ] A/B testing framework
- [ ] Production deployment with Docker
- [ ] Real-time data pipeline with Apache Kafka
- [ ] Advanced evaluation metrics (NDCG, MAP)

## ğŸ› Known Issues

- Model requires pre-training before using `app.py`
- API rate limits may affect large-scale scraping
- FAISS index needs rebuilding when model changes

## ğŸ“„ License

This project is part of ZovxLabs internship program. Please contact the organization for licensing details.

## ğŸ‘¥ Team

**ZovxLabs Internship Project**  
*Machine Learning & Data Engineering Team*

---

**Tech Stack**: PyTorch â€¢ Streamlit â€¢ FAISS â€¢ YouTube API â€¢ Scikit-learn â€¢ Pandas â€¢ NumPy
